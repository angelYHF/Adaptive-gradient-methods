{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1ZKKf5QGnxf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score, mean_absolute_error\n",
        "from scipy.stats import pearsonr\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Define the data file path\n",
        "data_path = \"/content/drive/My Drive/Adaptive gradient method/Adaptive gradient method from L_0 to L infnity/Final_pine_data.csv\"\n",
        "\n",
        "# Check if the data file exists\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"Error: The file '{data_path}' was not found.\")\n",
        "    print(\"Please make sure the file is correctly placed and the path is accessible.\")\n",
        "else:\n",
        "    # ----------------------------\n",
        "    # Load and Preprocess Data\n",
        "    # ----------------------------\n",
        "    data = pd.read_csv(data_path)\n",
        "    Y = data.iloc[:, :7].values  # 7 regression tasks\n",
        "    X = data.iloc[:, 7:].values  # SNPs/features\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Split the data into a training/validation set and a final test set\n",
        "    X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Define the search space for hyperparameter tuning\n",
        "    search_space = {\n",
        "        'num_leaves': hp.choice('num_leaves', np.arange(10, 100, 10, dtype=int)),\n",
        "        'max_depth': hp.choice('max_depth', np.arange(3, 15, 1, dtype=int)),\n",
        "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "        'n_estimators': hp.choice('n_estimators', np.arange(100, 500, 50, dtype=int)),\n",
        "        'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    }\n",
        "\n",
        "    # ----------------------------------------------------\n",
        "    # Function to train and evaluate a single trait model\n",
        "    # ----------------------------------------------------\n",
        "    def train_and_eval_for_trait(X_train, Y_train, X_test, Y_test, trait_idx):\n",
        "        \"\"\"\n",
        "        Trains and evaluates a LightGBM model for a single trait.\n",
        "        \"\"\"\n",
        "        Y_train_trait = Y_train[:, trait_idx]\n",
        "        Y_test_trait = Y_test[:, trait_idx]\n",
        "\n",
        "        # Objective function for Hyperopt\n",
        "        def objective(params):\n",
        "            model = lgb.LGBMRegressor(\n",
        "                objective='regression',\n",
        "                metric='rmse',\n",
        "                **params\n",
        "            )\n",
        "            model.fit(\n",
        "                X_train, Y_train_trait,\n",
        "                eval_set=[(X_test, Y_test_trait)],\n",
        "                callbacks=[lgb.early_stopping(100)]\n",
        "            )\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "            loss = mean_squared_error(Y_test_trait, y_pred)\n",
        "            return {'loss': loss, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "        # Run Bayesian Optimization to find the best hyperparameters\n",
        "        trials = Trials()\n",
        "        best = fmin(\n",
        "            fn=objective,\n",
        "            space=search_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials=trials,\n",
        "            rstate=np.random.default_rng(42)\n",
        "        )\n",
        "\n",
        "        # Get the best model from the trials\n",
        "        best_model = trials.best_trial['result']['model']\n",
        "\n",
        "        # Make predictions on the final test set\n",
        "        y_pred = best_model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        r2 = r2_score(Y_test_trait, y_pred)\n",
        "        mse = mean_squared_error(Y_test_trait, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(Y_test_trait, y_pred)\n",
        "        corr, _ = pearsonr(Y_test_trait, y_pred)\n",
        "\n",
        "        return {\n",
        "            'trait_index': trait_idx,\n",
        "            'r2': r2,\n",
        "            'mse': mse,\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'correlation': corr\n",
        "        }\n",
        "\n",
        "    # ----------------------------------------------------\n",
        "    # Train Models for All 7 Traits in Parallel\n",
        "    # ----------------------------------------------------\n",
        "    print(\"Training LightGBM models for 7 traits...\")\n",
        "\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(train_and_eval_for_trait)(X_trainval, Y_trainval, X_test, Y_test, i)\n",
        "        for i in range(Y_trainval.shape[1])\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # Display Results\n",
        "    # ----------------------------\n",
        "    print(\"\\n--- Final Test Evaluation for all Traits ---\")\n",
        "    for res in results:\n",
        "        print(f\"\\nTrait {res['trait_index'] + 1}:\")\n",
        "        print(f\"  R2: {res['r2']:.4f}\")\n",
        "        print(f\"  MSE: {res['mse']:.4f}\")\n",
        "        print(f\"  RMSE: {res['rmse']:.4f}\")\n",
        "        print(f\"  MAE: {res['mae']:.4f}\")\n",
        "        print(f\"  Pearson Correlation: {res['correlation']:.4f}\")"
      ],
      "metadata": {
        "id": "AMVm8SS2GoTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}